\documentclass[english]{article}
\usepackage[latin1]{inputenc}
\makeatletter
\usepackage{babel}
\usepackage{natbib}
\usepackage{times}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{url}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{amsmath}
\graphicspath{{./images/}}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\frametrans}[3]{{}_{#1}{#3}^{#2}}
\makeatother
\addtolength{\textwidth}{4cm}
\addtolength{\hoffset}{-2cm}
\begin{document}

\title{ITTIK}
\author{Olaf Booij}

\maketitle

The KITTI dataset is a standard for evaluating R\&D in autonomous
driving and mapping. An important part of the used sensor setup is a
surround LiDAR sensor which captures ranges and reflectivity of the
structures and objects around the vehicle.
This LiDAR data is not presented as raw sensor readings, which are hard
to interpret. Rather, the data is preprocessed into easy to comprehend
single scan 3D point clouds measured in a single 360 degrees rotation.
Generic point cloud software can be used to visualize and process such
data.

A drawback of the point clouds is that it is difficult to get the
precise time for each of the 3d point measurements. In addition, it is
difficult to compute the exact origin of the cast LiDAR rays. A more
general concern is that the point clouds do not reflect the dense and
structured form of the LiDAR measurement.

ITTIK tries to get back the raw LiDAR sensor data by undoing the steps
performed during the KITTI preprocessing. It does so using the KITTI
point clouds, as well as the available calibration data.

\section{Velodyne data}
% sensor
The LiDAR sensor used for the KITTI dataset is a Velodyne HDL-64E. This
device fires its 64 individual lasers with a frequency of 20 KHz, while
the device is rotating at a rate of 10 Hz, resulting in approximately
130,000 measurements per scan and 1.3 million measurements per
second. The 64 lasers do not fire at the same time. Instead, at each
timestep, two of the lasers fire in a fixed sequence. Because the device
keeps on rotating, each pair of points has a unique measurement time as
well as a unique device orientation.

For each firing laser, the distance and reflectivity of the scene point
is measured. In addition, for each lower and upper block of 32 laser
fires the rotational position is measured. For each packet of 6 lower
and upper blocks, a timestamp is sent, which can be used to
synchronize the data with measurements from other sensors.

The rays of each laser have a different vertical and horizontal
direction. In addition, the lasers are distributed over 4 locations on
the device resulting in a slightly different offset of the ray origin.
The exact value of these directions and offsets are given in the
calibration stored on the device (more on this in the next section).
In Figure~\ref{fig:directions} the different directions of the laser
rays are shown. As can be seen the vertical view-angle is approximately
28 degrees and the horizontal view-angle 19 degrees.

\begin{figure}
    \centering
    %\input{directions.pdf_tex}
    \def\svgwidth{\columnwidth}
    \scalebox{0.9}{
    \def\svgwidth{.6 \columnwidth}
      \input{directions.pdf_tex}
    }
    \caption{Direction of each laser, plotted with there index, as
    indicated in the calibration file in degrees.}
		\label{fig:directions}
\end{figure}

It is important to understand the implications of this horizontal view
angle. Points from the same scan that are close to each other in the
scene, have a different measurement time. Take for example laser \#41
and laser \#46 (see Figure~\ref{fig:directions}). Verticaly, they are
``neighbors'', but horizontally they are 19 degrees apart.

Thus, it is not easy to get information from the measurements of a
single fire of all lasers. It is like a depth camera where only 64
pixels are working spread over the image plane. A point cloud
representations is much more useful.

Still, for this point cloud we should consider that the device for the
example lasers has to rotate 19 degrees, before they measure the same
structure. Taking the rotation speed into account, two very close points
in the scene will have been measured with a time difference of
$\frac{19}{360} 100 \, \mbox{ms}= 5 \, \mbox{ms}$.

This time difference has to be taken into acount of course when
processing the data. KITTI contains, in addition to the ``raw'' point
clouds, motion corrected data, in which the vehicle motion is
compensatad for, for each laser. For moving objects, however, this is of
course more difficult.
% ... example of moving object in motion corrected data

Nevertheless, this project is mainly meant to counter another
disadvantage of the point cloud representation. The spread of the
lasers, and their non-monotinic firing behavior (more about that later),
results in a non-uniform point cloud, hard to feed into standard image
processing tools such as convolutional neural networks. This is the main
reason to try to get the original Velodyne data back.
% ... example of piece of point cloud

\section{Preprocessing}
\label{sec:preproc}
In order to easily interpret the Velodyne data, the raw byte stream is
preprocessed using a fixed process, as given in the User's Manual and
Programming Guide. This process has two parts. The first part, computes for
each laser fire from the laser id, the measured distance and measured
rotational position, the 3d point location. The second part, computes
for the raw intensity measurement, the surface reflectivity of the
measured point. We will (for now) only focus on the first part.

The preprocessing uses some parameters. Some of these are fixed for all
devices of the used LiDAR type, such as the location of the laser on the
device. There are, however, also device specific parameters, such as the
precise direction of the lasers, which are determined in the factory
using a specific calibration procedure and stored on the device. These
values are also transmitted by the device to be stored and used by the
preprocessing procedure.

For the KITTI dataset these calibration values are provided on the
website in the standard xml form:
\path{velodynecalib_S2_factory_flatness_intensity.xml}. The values in
this file are used in ITTIK, and for visualizations in this document
such as in Figure~\ref{fig:directions}.

In the following, we describe the main part of the preprocessing
algorithm.

\begin{eqnarray}
  p'(d, \theta, l, \Delta d) &=& \left(
           \begin{array}{l}
             (d + \Delta d) * \cos{\phi_l} * \sin{\theta} - h_l \cos{\theta} \nonumber \\
             (d + \Delta d) * \cos{\phi_l} * \cos{\theta} + h_l \sin{\theta} \nonumber \\
             (d + \Delta d) * \sin{\phi_l} + v_l
           \end{array}
         \right)
\end{eqnarray}

\begin{eqnarray}
  \Delta dx &=& \Delta dx_l + \frac{(p_x'(d, \theta, l, \Delta d_l)(\Delta d_l - \Delta dx_l) - 2.40)}{(25.04 - 2.40)} \nonumber \\
  \Delta dy &=& \Delta dy_l + \frac{(p_y'(d, \theta, l, \Delta d_l)(\Delta d_l - \Delta dy_l) - 1.93)}{(25.04 - 1.93)} \nonumber
\end{eqnarray}

\begin{eqnarray}
  p(d, \theta, l) &=& \left(
           \begin{array}{l}
              p_x'(d, \theta, l, \Delta dx) \nonumber \\
              p_y'(d, \theta, l, \Delta dy) \nonumber \\
              p_z'(d, \theta, l, \Delta dy) \nonumber
           \end{array}
         \right)
\end{eqnarray}

\begin{eqnarray}
  d &=& d_u + \Delta d_{\mbox{c}} \nonumber \\
  \theta &=& \theta_u - \theta_{\mbox{c}} \nonumber \\
  d' &=& d * \cos{\phi_{\mbox{c}}} \nonumber \\
  x &=& |d' * \sin{\theta} - h_{\mbox{c}} * \cos{\theta}| \nonumber \\
  y &=& |d' * \cos{\theta} + h_{\mbox{c}} * \sin{\theta}| \nonumber \\
  \Delta dx &=& (\Delta d_{\mbox{c}} - \Delta dx_{\mbox{c}}) * (x - 2.40) / (25.04 - 2.40) + \Delta dx_{\mbox{c}} \nonumber \\
  \Delta dy &=& (\Delta d_{\mbox{c}} - \Delta dy_{\mbox{c}}) * (y - 1.93) / (25.04 - 1.93) + \Delta dy_{\mbox{c}} \nonumber \\
  d_x &=& d_u + \Delta dx \nonumber \\
  d'_x &=& d_x * \cos{\phi_{\mbox{c}}} \nonumber \\
  d_y &=& d_u + \Delta dy \nonumber \\
  d'_y &=& d_y * \cos{\phi_{\mbox{c}}} \nonumber \\
  p &=&  \left(
           \begin{array}{c}
             d'_x * \sin{\theta} - h_{\mbox{c}} \cos{\theta} \nonumber \\
             d'_y * \cos{\theta} + h_{\mbox{c}} \sin{\theta} \nonumber \\
             d_y * \sin{\phi_{\mbox{c}}} + v_{\mbox{c}}
           \end{array}
         \right)
\end{eqnarray}




% Note, that the number of bytes used by the device to transmit its
% measurements is kept low, while preserving the information.
% The storage of the (uncompressed) millimeter accurate point clouds is
% about 2 times larger than the format used by the sensor.
% 17+17+11+7 bit
% 16+8

\section{Reversing the preprocessing}
% laser number
% iterative algorithm

\section{Results}
% error when reprojecting distance/position
% position alignment

\bibliographystyle{apalike}
\bibliography{test}

\end{document}

\section{Thingies to copy-paste}
\subsection{subbla}
\subsubsection{subsubbla}
\paragraph{}
\par{parbla}
\par


\begin{figure}
  \begin{center}
    \subfigure[][SubCaption1]
      {
       \label{subfig:name1}
       \includegraphics[width=\textwidth]{nogNiks}
      }
    \subfigure[][SubCaption2]
      {
       \label{subfig:name2}
       \includegraphics[height=8cm]{nogNiks}
      }
      \caption{Caption}
  \label{fig:name}
  \end{center}
\end{figure}
\begin{figure}
  \begin{center}
    \includegraphics[width=\textwidth]{nogNiks}
    %\scalebox{.5}{ \input{images/name.pstex_t} }
    \caption{Caption}
    \label{fig:name}
  \end{center}
\end{figure}
\begin{itemize}
\item
\item
\end{itemize}
\begin{description}
\item
\end{description}
\begin{enumerate}
\item
\end{enumerate}
\begin{equation}
  0 \neq 1
\end{equation}
\begin{eqnarray}
  0 &\neq& 1 \\
  A
         \left[
           \begin{array}{ccc}
             1 & 0 & 0 \\
             0 & 1 & 0 \\
             0 & 0 & 1
           \end{array}
         \right]
  A^T
  &=& B
\end{eqnarray}
\begin{table}
  %\renewcommand{\arraystretch}{1.2}
  \caption{}
  \label{tab:mane}
  \begin{center}
    \begin{tabular}{|c|c||c|}
      \hline
      \multicolumn{2}{|c||}{A} & B \\ \hline
       1 & 1 & 1 \\ \hline
       1 & 1 & 1 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

