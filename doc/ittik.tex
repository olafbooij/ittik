\documentclass[english]{article}
\usepackage[latin1]{inputenc}
\makeatletter
\usepackage{babel}
\usepackage{natbib}
\usepackage{times}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{url}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{amsmath}
\graphicspath{{./images/}}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\frametrans}[3]{{}_{#1}{#3}^{#2}}
\makeatother
\addtolength{\textwidth}{4cm}
\addtolength{\hoffset}{-2cm}
\begin{document}

\title{ITTIK}
\author{Olaf Booij}

\maketitle

The KITTI dataset is a standard for evaluating R\&D in autonomous
driving and mapping. An important part of the used sensor setup is a
surround LiDAR sensor which captures ranges and reflectivity of the
structures and objects around the car.
This LiDAR data is not presented as raw sensor readings, which are hard
to interpret. Rather, the data is preprocessed into easy to comprehend
single scan 3D point clouds measured in a single 360 degrees rotation.
Generic point cloud software can be used to visualize and process such
data.

A drawback of the point clouds is that it is difficult to get the
precise time for each of the 3d point measurements. In addition, it is
difficult to compute the exact origin of the cast LiDAR rays. A more
general concern is that the point clouds do not reflect the dense and
structured form of the LiDAR measurement.

ITTIK tries to get back the raw LiDAR sensor data by undoing the steps
performed during the KITTI preprocessing. It does so using the KITTI
point clouds, as well as the available calibration data.

\section{Velodyne data}
% sensor
The LiDAR sensor used for the KITTI dataset is a Velodyne HDL-64E. This
device fires its 64 individual lasers with a frequency of 20 KHz, while
the device is rotating at a rate of 10 Hz, resulting in approximately
130,000 measurements per scan and 1.3 million measurements per
second. The 64 lasers do not fire at the same time. Instead, at each
timestep, two of the lasers fire in a fixed sequence. Because the device
keeps on rotating, each pair of points has a unique measurement time as
well as a unique device orientation.

The rays of each laser have a different vertical and horizontal
direction. In addition, the lasers are distributed over 4 locations on
the device resulting in a slightly different offset of the ray origin.
The exact value of these directions and offsets are given in the
calibration stored on the device (more on this in the next section).
In Figure~\ref{fig:directions} the different directions of the laser
rays are shown. As can be seen the vertical view-angle is approximately
28 degrees and the horizontal view-angle 19 degrees.

\begin{figure}
    \centering
    \def\svgwidth{.8 \columnwidth}
    \input{directions.pdf_tex}
    %\def\svgwidth{\columnwidth}
    %\scalebox{0.8}{\input{directions.pdf_tex}}
    \caption{Direction of each laser as indicated in the calibration
    file in degrees.}
		\label{fig:directions}
\end{figure}

It is important to understand the implications of this horizontal view
angle. Measured points from the same scan that are close to each other
in the scene, have been measured at a slightly different time. Take for
example laser \#41 and laser \#46 (see Figure~\ref{fig:directions}).
Verticaly, they are ``neighbors'', but horizontally they are 19 degrees
apart. This means that the device has to rotate 19 degrees, before laser
\#46 points in the direction where laser \#41 was pointing. Taking the
rotation speed into account, two very close points in the scene will
have been meaured with a time difference of $\frac{19}{360} 100 \,
\mbox{ms}= 5 \, \mbox{ms}$.


%Moving car

% quantify "error" given assumptions

\section{Preprocessing}
\label{sec:preproc}
% algorithm
% calibration file

\section{Reversing the preprocessing}
% laser number
% iterative algorithm

\section{Results}
% error when reprojecting distance/position
% position alignment

\bibliographystyle{apalike}
\bibliography{test}

\end{document}

\section{Thingies to copy-paste}
\subsection{subbla}
\subsubsection{subsubbla}
\paragraph{}
\par{parbla}
\par


\begin{figure}
  \begin{center}
    \subfigure[][SubCaption1]
      {
       \label{subfig:name1}
       \includegraphics[width=\textwidth]{nogNiks}
      }
    \subfigure[][SubCaption2]
      {
       \label{subfig:name2}
       \includegraphics[height=8cm]{nogNiks}
      }
      \caption{Caption}
  \label{fig:name}
  \end{center}
\end{figure}
\begin{figure}
  \begin{center}
    \includegraphics[width=\textwidth]{nogNiks}
    %\scalebox{.5}{ \input{images/name.pstex_t} }
    \caption{Caption}
    \label{fig:name}
  \end{center}
\end{figure}
\begin{itemize}
\item
\item
\end{itemize}
\begin{description}
\item
\end{description}
\begin{enumerate}
\item
\end{enumerate}
\begin{equation}
  0 \neq 1
\end{equation}
\begin{eqnarray}
  0 &\neq& 1 \\
  A
         \left[
           \begin{array}{ccc}
             1 & 0 & 0 \\
             0 & 1 & 0 \\
             0 & 0 & 1
           \end{array}
         \right]
  A^T
  &=& B
\end{eqnarray}
\begin{table}
  %\renewcommand{\arraystretch}{1.2}
  \caption{}
  \label{tab:mane}
  \begin{center}
    \begin{tabular}{|c|c||c|}
      \hline
      \multicolumn{2}{|c||}{A} & B \\ \hline
       1 & 1 & 1 \\ \hline
       1 & 1 & 1 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

